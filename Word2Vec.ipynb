{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1l_XAaodG8KhvBWLyXAujQkSZU83hqqbj",
      "authorship_tag": "ABX9TyMWVmZ2SBRBXRBFdXfuqFQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavanajamalpur/Basics_git/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "nltk.download(\"brown\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thi6pHaFw00w",
        "outputId": "c647bf61-f1f9-4d5e-cf01-6eecedc45a6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data to lowercase all words and remove single punctuation words\n",
        "document = brown.sents()\n",
        "data = []\n",
        "for sent in document:\n",
        "  new_sent = []\n",
        "  for word in sent:\n",
        "    new_word = word.lower()\n",
        "    if new_word[0] not in string.punctuation:\n",
        "      new_sent.append(new_word)\n",
        "  if len(new_sent) > 0:\n",
        "    data.append(new_sent)\n",
        ""
      ],
      "metadata": {
        "id": "LjlS1eCHw6CC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "nltk.download(\"brown\")\n",
        "\n",
        "# Preprocessing data to lowercase all words and remove single punctuation words\n",
        "document = brown.sents()\n",
        "data = []\n",
        "for sent in document:\n",
        "  new_sent = []\n",
        "  for word in sent:\n",
        "    new_word = word.lower()\n",
        "    if new_word[0] not in string.punctuation:\n",
        "      new_sent.append(new_word)\n",
        "  if len(new_sent) > 0:\n",
        "    data.append(new_sent)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWLK7CSbw8wD",
        "outputId": "02226f5c-fe35-49ab-bf64-60bff5c95541"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample sentences for training the Word2Vec model\n",
        "sentences = [\n",
        "    \"Machine learning is fascinating\",\n",
        "    \"Natural language processing is important for AI\",\n",
        "    \"Word study capture semantic meanings\"\n",
        "]\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Training the Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Finding similar words\n",
        "similar_words = model.wv.most_similar(\"learning\")\n",
        "\n",
        "# Printing similar words\n",
        "print(\"Similar words to 'learning':\")\n",
        "for word in similar_words:\n",
        "    print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHErD3q1xmmS",
        "outputId": "49cf4b08-4f5b-4672-f8bf-269f991858ef"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words to 'learning':\n",
            "('study', 0.25290459394454956)\n",
            "('meanings', 0.13725271821022034)\n",
            "('word', 0.04410674050450325)\n",
            "('machine', 0.027008363977074623)\n",
            "('ai', 0.01281161978840828)\n",
            "('capture', 0.006598459556698799)\n",
            "('language', -0.0011978191323578358)\n",
            "('for', -0.025461023673415184)\n",
            "('is', -0.04125342145562172)\n",
            "('fascinating', -0.07639002799987793)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}